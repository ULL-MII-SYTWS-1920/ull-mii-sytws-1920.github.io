---
layout: post
title:  "Clase del Lunes 09/12/2019"
categories: Clases
---



# Clase del Lunes 09/12/2019

## Anuncio

Incidencia en el servicio IaaS y sistemas de cómputo. Contacto: http://soporte.ull.es/stic (soporte@ull.es). 
Máquinas apagadas.

## Transforming Data and Testing Continuously. Chapter 5 of the Book Node.js the Right Way

Este es el primer capítulo de una serie que cubre los capítulos del 5 al 9 en el que se construye una aplicación Web.

En este capítulos 5 vamos a:

* Descargar desde el Proyecto Gutenberg (ebooks gratuitos) el catálogo de libros en [Resource Description Framework RDF](https://en.wikipedia.org/wiki/Resource_Description_Framework). 

  [![Guttenberg project](/assets/images/guttenberg.png)](http://www.gutenberg.org/)

El RDF es una familia de especificaciones de la World Wide Web Consortium (W3C) para describir en XML los datos que aparecen en un recurso web.

* Extraeremos del fichero RDF/XML la información que nos interesa, produciendo como salida un fichero JSON con la misma
   - La idea es escribir algo así como un programa `rdf-to-json.js` que funcione así:
   ```
   ~/.../transforming-data-and-testing-continuously-chapter-5/databases(master)]$ ./rdf-to-json.js ../data/cache/epub/12/pg12.rdf 
   ```

  - Que deberá producir una  salida parecida a esta:

   ```json
        {
        "id": 12,
        "title": "Through the Looking-Glass",
        "authors": [
            "Carroll, Lewis"
        ],
        "subjects": [
            "Fantasy literature"
        ]
        }
    ```
* Estos JSON van a guardarse en una base de Datos denominada Elastic Search que va a ser usada en el capítulo 6 del libro (Commanding Databases). 
  - Elasticsearch es una base de datos NoSQL que funciona como un servicio REST a la que se accede vía HTTP  y que almacena e indexa documentos JSON. En el capítulo 6 se construye un programa de línea de comandos que permite interactuar con la base de datos que se crea en el capítulo 5.
 - Este es el esquema de trabajo para los dos capítulos:
  - ![xml 2 json and json 2 elastic search](/assets/images/ch5-xml-2-json-ch6-2-es.png)


## Line Delimited JSON

No vamos a usar JSON como formato de salida, sino Line Delimited JSON.

[Line Delimited JSON (JDL)](https://en.wikipedia.org/wiki/JSON_streaming#Line-delimited_JSON), newline-delimited **JSON** (**NDJSON**), and **JSON lines** (**JSONL**) are three terms for equivalent formats of JSON streaming.

Streaming makes use of the fact that the JSON format does not allow newline and return characters within primitive values (in strings those must be escaped as `\n` and `\r`, respectively) and that most JSON formatters default to not including any whitespace, including newlines and returns.
These features allow the <u>newline</u> and/or return characters to be used as a delimiter.



This format is documented at the [JSON Lines website](http://jsonlines.org/).

This example shows two JSON objects (the implicit newline characters at the end of each line are not shown):

```json
{"some":"thing\n"}
```

```json
{"may":{"include":"nested","objects":["and","arrays"]}}
```

The use of a newline as a delimiter enables this format to work very well with [traditional line-oriented Unix tools](https://en.wikipedia.org/wiki/Pipeline_(Unix)).

## Estructura de directorios

Este es un ejemplo de como estructurar este proyecto:

⇐
LEFTWARDS DOUBLE ARROW
Unicode: U+21D0, UTF-8: E2 87 90

```
$ tree -s  -I 'node_modules*|epub*|jim*|images'
.
├── [        192]  data
│   ├── [        294]  README.md
│   ├── [   13005066]  bulk_pg.ldj       ⇐ Fichero en formato LDJ con todo el catálogo
│   ├── [   10809492]  bulk_result.json  ⇐ Lo generaremos en el capítulo 6
│   └── [         96]  cache             ⇐ Donde quedarán los ficheros RDF de la descarga
└── [        256]  databases
    ├── [      38863]  README.md
    ├── [         96]  lib
    │   └── [       3665]  parse-rdf.js
    ├── [        786]  rdf-to-bulk.js
    ├── [        338]  rdf-to-json.js
    └── [        128]  test
        ├── [       1101]  parse-rdf-test.js
        └── [      12393]  pg132.rdf

5 directories, 9 files
```

En el directorio `data` guardaremos los datos  descargados de Guttenberg y en el directorio `databases` nuestro código: ejecutables, librerías y las pruebas.

## Descarga de los datos

En esta página  encontrará el catálogo completo de Guttenberg en formato RDF/XML:

[![](/assets/images/guttenberg-catalog.png)](https://www.gutenberg.org/wiki/Gutenberg:Feeds#The_Complete_Project_Gutenberg_Catalog)

Para descargarlo nos  posicionamos en el directorio adecuado y podemos usar `curl`. El fichero está compactado:

```
~/sol-nodejs-the-right-way/transforming-data-and-testing-continuously-chapter-5(master)]$ sed -ne '/c5-get/,/^$/p'  ~/sol-nodejs-the-right-way/gulpfile.js 
```

```js
gulp.task("c5-get-guttenberg", shell.task(
  
    'cd transforming-data-and-testing-continuously-chapter-5/data && ' +
    'curl -O https://www.gutenberg.org/cache/epub/feeds/rdf-files.tar.bz2 &&' +
    'tar -xvjf rdf-files.tar.bz2'
));
```

* `curl option -O, --remote-name`
  -  Write  output to a local file named like the remote file we get. (Only the file part of the remote file is used, the path is cut off.) The file will be saved in the current working directory. If you want the file saved in a different directory,  make  sure        you change the current working directory before invoking curl with this option.  The remote file name to use for saving is extracted from the given URL, nothing else, and if it already exists it will be overwritten.
*  `tar -xvjf rdf-files.tar.bz2`
  -  `-x`      Extract to disk from the archive.  If a file with the same name appears more than once in the archive, each copy will be extracted, with later copies overwriting (replacing) earlier copies.
  -  `-j`  (c mode only) Compress the resulting archive with bzip2(1).  In extract or list modes, this option is ignored.  Note that unlike other tar implementations, this implementation recognizes bzip2 compression automatically when reading archives.
  -  `-f file`  Read the archive from or write the archive to the specified file.  The filename can be for standard input or standard output.
  -   `-v`  Produce verbose output.  In create and extract modes, tar will list each file name as it is read from or written to the archive.  In list mode, tar will produce output similar to that of ls(1).  Additional -v options will provide additional detail.

Cuando ejecutamos esta secuencia de comandos crearemos en el directorio `data` los ficheros `*.rdf`, una por libro:

```
x cache/epub/0/pg0.rdf
x cache/epub/1/pg1.rdf
x cache/epub/10/pg10.rdf
...
x cache/epub/9998/pg9998.rdf
x cache/epub/9999/pg9999.rdf
x cache/epub/999999/pg999999.rdf
...
```

Esto nos deja en `cache/epub/` un montón de directorios numerados:

```
$ ls data/cache/epub/ | head -n 4
0
1
10
100
$ ls data/cache/epub/ | tail -n 4
9999
999999
DELETE-52276
DELETE-55495
```

## Analizando la estructura de los ficheros RDF

Por ejemplo, aquí están los contenidos de [data/cache/epub/132/pg132.rdf](/tema3-web/pg132)

The important pieces of information that we’d like to extract are as follows:

* The Gutenberg ID (132)
* The book’s title
* The list of authors (agents) 
* The list of subjects

```
$  ./rdf-to-json.js ../data/cache/epub/132/pg132.rdf
```

```json 
{
  "id": 132,
  "title": "The Art of War",
  "authors": [
    "Sunzi, active 6th century B.C.",
    "Giles, Lionel"
  ],
  "subjects": [
    "Military art and science -- Early works to 1800",
    "War -- Early works to 1800"
  ]
}
```

## Las Pruebas


### Mocha y Chai

```
$ cd databases
$ npm init -y
$ npm install --save-dev --save-exact mocha chai
```

### ejecución de las Pruebas

```
[~/sol-nodejs-the-right-way(master)]$ jq .scripts package.json 
```

```json
{
  "test-databases": "mocha transforming-data-and-testing-continuously-chapter-5/databases/test/parse-rdf-test.js",
  "test-debug-databases": "mocha --inspect-brk --no-timeouts transforming-data-and-testing-continuously-chapter-5/databases/test/parse-rdf-test.js",
  "test:watch-databases": "mocha --watch --reporter min transforming-data-and-testing-continuously-chapter-5/databases/test/parse-rdf-test.js",
}
```


### BDD, TDD and The Red-Green-Refactor cycle


1. Add new criteria to the test.
2. Run the test and see that it fails.
3. Modify the code being tested.
4. Run the test and see that it passes.

[![https://files.realpython.com/media/tdd.0904607f8ec9.png](https://files.realpython.com/media/tdd.0904607f8ec9.png)](https://medium.com/@sukorenomw/why-tdd-test-driven-development-a1bc983a2cc0)

We keep this cycle going over and over again:

1. We write the test before a single line of implementation code is written.
    * That test will serve as a guideline what to build and to make sure we don’t break anything in the future that prevents the regular flow from working.
    * We describe each unit of the system through a failing test
2. We write the code to make it pass
3. Then, we can refactor it if necessary

### Código de las Pruebas

```
cp ../data/cache/epub/132/pg132.rdf test/
[~/.../Capitulo5/databases(master)]$ tree test/
test/
├── parse-rdf-test.js
└── pg132.rdf
```

```
$ cat databases/test/parse-rdf-test.js 
```

```js
'use strict';

const fs = require('fs');
const expect = require('chai').expect;
const parseRDF = require('../lib/parse-rdf.js');
const rdf = fs.readFileSync(`${__dirname}/pg132.rdf`);

describe("Chapter 5: Transforming Data and Testing Continuously", () => {
  describe('parseRDF', () => {
    it('should be a function', () => {
      debugger;
      expect(parseRDF).to.be.a('function');
    });
    it('should parse RDF content', () => {
      const book = parseRDF(rdf);
      // https://www.chaijs.com/api/bdd/#method_language-chains
      expect(book).to.be.a('object');

      expect(book).to.have.a.property('id', 132);

      expect(book).to.have.a.property('title', 'The Art of War');

      expect(book).to.have.a.property('authors').that.is.an('array').with.lengthOf(2).
      and.contains('Sunzi, active 6th century B.C.').
      and.contains('Giles, Lionel');

      expect(book).to.have.a.property('subjects').that.is.an('array').with.lengthOf(2).
      and.contains('Military art and science -- Early works to 1800').
      and.contains('War -- Early works to 1800');
    });
  });
});
```

### Depurando las Pruebas


Mocha options for debugging. The options:

```
--debug, --inspect, --debug-brk, --inspect-brk, debug, inspect
```

Enables Node.js' debugger or inspector.

Use `--inspect / --inspect-brk / --debug / --debug-brk`  to launch the V8 inspector for use with Chrome Dev Tools.

Use `inspect / debug` to launch Node.js' internal debugger.

All of these options are mutually exclusive.

Implies `--no-timeout`.

```
[~/.../p9-t3-transforming-data/transforming-data-and-testing-continuously-chapter-5(master)]$ npm run test-debug-databases

> nodejs-8-the-right-way@1.0.0 test-debug-databases /Users/casiano/local/src/CA/sol-nodejs-the-right-way
> mocha --inspect-brk --no-timeouts transforming-data-and-testing-continuously-chapter-5/databases/test/parse-rdf-test.js

Debugger listening on ws://127.0.0.1:9229/db1b1cee-1632-4541-9ef9-608b2943c3a3
For help, see: https://nodejs.org/en/docs/inspector
Debugger attached.
```

![/assets/images/chrome-debug-mocha.png](/assets/images/chrome-debug-mocha.png)

## Extracting Data from XML with Cheerio

```
[~/.../Capitulo5/databases(master)]$ cat lib/parse-rdf.js 
```

```js
'use strict';

const cheerio = require('cheerio');

module.exports = rdf => {
    const $ = cheerio.load(rdf);
    const book = {};
    book.id = +$('pgterms\\:ebook').attr('rdf:about').replace('ebooks/', '');
    book.title = $('dcterms\\:title').text();
    book.authors = $('pgterms\\:agent pgterms\\:name')
        .toArray().map(elem => $(elem).text());
        
    book.subjects = $('[rdf\\:resource$="/LCSH"]')
        .parent().find('rdf\\:value')
        .toArray().map(elem => $(elem).text());

    book.subject = $('[rdf\\:resource$="/LCC"]')
        .parent().find('rdf\\:value').text();

    var elementos = [];

    $('dcterms\\:hasFormat')
        .find('pgterms\\:file').each((y, j) => 
            elementos.push([
                $(j).attr('rdf:about'), 
                $(j).find('dcterms\\:extent').text(),
                $(j).find('rdf\\:value').text() 
            ])
        );

    book.dowload = elementos;
                    

    return book;
};
```