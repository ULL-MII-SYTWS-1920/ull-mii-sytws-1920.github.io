---
layout: post
title:  "Clase del Lunes 09/12/2019"
categories: Clases
---



# Clase del Lunes 09/12/2019

## Anuncio

Incidencia en el servicio IaaS y sistemas de cómputo. Contacto: http://soporte.ull.es/stic (soporte@ull.es). 
Máquinas apagadas.

## Commanding Data Bases. Chapter 5 of the Book Node.js the Right Way

Este es el primer capítulo de una serie que cubre los capítulos del 5 al 9 en el que se construye una aplicación Web.

En este capítulos 5 vamos a:

* Descargar desde el Proyecto Gutenberg (ebooks gratuitos) el catálogo de libros en [Resource Description Framework RDF](https://en.wikipedia.org/wiki/Resource_Description_Framework). 

  [![Guttenberg project](/assets/images/guttenberg.png)](http://www.gutenberg.org/)

El RDF es una familia de especificaciones de la World Wide Web Consortium (W3C) para describir en XML los datos que aparecen en un recurso web.

* Extraeremos del fichero RDF/XML la información que nos interesa, produciendo como salida un fichero JSON con la misma
   - La idea es escribir algo así como un programa `rdf-to-json.js` que funcione así:
   ```
   ~/.../transforming-data-and-testing-continuously-chapter-5/databases(master)]$ ./rdf-to-json.js ../data/cache/epub/12/pg12.rdf 
   ```

  - Que deberá producir una  salida parecida a esta:

   ```json
        {
        "id": 12,
        "title": "Through the Looking-Glass",
        "authors": [
            "Carroll, Lewis"
        ],
        "subjects": [
            "Fantasy literature"
        ]
        }
    ```
* Estos JSON van a guardarse en una base de Datos denominada Elastic Search que va a ser usada en el capítulo 6 del libro (Commanding Databases). 
  - Elasticsearch es una base de datos NoSQL que funciona como un servicio REST a la que se accede vía HTTP  y que almacena e indexa documentos JSON. En el capítulo 6 se construye un programa de línea de comandos que permite interactuar con la base de datos que se crea en el capítulo 5.
 - Este es el esquema de trabajo para los dos capítulos:
  - ![xml 2 json and json 2 elastic search](/assets/images/ch5-xml-2-json-ch6-2-es.png)


## Line Delimited JSON

No vamos a usar JSON como formato de salida, sino Line Delimited JSON.

[Line Delimited JSON (JDL)](https://en.wikipedia.org/wiki/JSON_streaming#Line-delimited_JSON), newline-delimited **JSON** (**NDJSON**), and **JSON lines** (**JSONL**) are three terms for equivalent formats of JSON streaming.

Streaming makes use of the fact that the JSON format does not allow newline and return characters within primitive values (in strings those must be escaped as `\n` and `\r`, respectively) and that most JSON formatters default to not including any whitespace, including newlines and returns.
These features allow the <u>newline</u> and/or return characters to be used as a delimiter.



This format is documented at the [JSON Lines website](http://jsonlines.org/).

This example shows two JSON objects (the implicit newline characters at the end of each line are not shown):

```json
{"some":"thing\n"}
```

```json
{"may":{"include":"nested","objects":["and","arrays"]}}
```

The use of a newline as a delimiter enables this format to work very well with [traditional line-oriented Unix tools](https://en.wikipedia.org/wiki/Pipeline_(Unix)).

## Estructura de directorios

Este es un ejemplo de como estructurar este proyecto:

⇐
LEFTWARDS DOUBLE ARROW
Unicode: U+21D0, UTF-8: E2 87 90

```
$ tree -s  -I 'node_modules*|epub*|jim*|images'
.
├── [        192]  data
│   ├── [        294]  README.md
│   ├── [   13005066]  bulk_pg.ldj       ⇐ Fichero en formato LDJ con todo el catálogo
│   ├── [   10809492]  bulk_result.json  ⇐ Lo generaremos en el capítulo 6
│   └── [         96]  cache             ⇐ Donde quedarán los ficheros RDF de la descarga
└── [        256]  databases
    ├── [      38863]  README.md
    ├── [         96]  lib
    │   └── [       3665]  parse-rdf.js
    ├── [        786]  rdf-to-bulk.js
    ├── [        338]  rdf-to-json.js
    └── [        128]  test
        ├── [       1101]  parse-rdf-test.js
        └── [      12393]  pg132.rdf

5 directories, 9 files
```

En el directorio `data` guardaremos los datos  descargados de Guttenberg y en el directorio `databases` nuestro código: ejecutables, librerías y las pruebas.

## Descarga de los datos

En esta página  encontrará el catálogo completo de Guttenberg en formato RDF/XML:

[![](/assets/images/guttenberg-catalog.png)](https://www.gutenberg.org/wiki/Gutenberg:Feeds#The_Complete_Project_Gutenberg_Catalog)

Para descargarlo nos  posicionamos en el directorio adecuado y podemos usar `curl`. El fichero está compactado:

```
~/sol-nodejs-the-right-way/transforming-data-and-testing-continuously-chapter-5(master)]$ sed -ne '/c5-get/,/^$/p'  ~/sol-nodejs-the-right-way/gulpfile.js 
```

```js
gulp.task("c5-get-guttenberg", shell.task(
  
    'cd transforming-data-and-testing-continuously-chapter-5/data && ' +
    'curl -O https://www.gutenberg.org/cache/epub/feeds/rdf-files.tar.bz2 &&' +
    'tar -xvjf rdf-files.tar.bz2'
));
```

* `curl option -O, --remote-name`
  -  Write  output to a local file named like the remote file we get. (Only the file part of the remote file is used, the path is cut off.) The file will be saved in the current working directory. If you want the file saved in a different directory,  make  sure        you change the current working directory before invoking curl with this option.  The remote file name to use for saving is extracted from the given URL, nothing else, and if it already exists it will be overwritten.
*  `tar -xvjf rdf-files.tar.bz2`
  -  `-x`      Extract to disk from the archive.  If a file with the same name appears more than once in the archive, each copy will be extracted, with later copies overwriting (replacing) earlier copies.
  -  `-j`  (c mode only) Compress the resulting archive with bzip2(1).  In extract or list modes, this option is ignored.  Note that unlike other tar implementations, this implementation recognizes bzip2 compression automatically when reading archives.
  -  `-f file`  Read the archive from or write the archive to the specified file.  The filename can be for standard input or standard output.
  -   `-v`  Produce verbose output.  In create and extract modes, tar will list each file name as it is read from or written to the archive.  In list mode, tar will produce output similar to that of ls(1).  Additional -v options will provide additional detail.

Cuando ejecutamos esta secuencia de comandos crearemos en el directorio `data` los ficheros `*.rdf`, una por libro:

```
x cache/epub/0/pg0.rdf
x cache/epub/1/pg1.rdf
x cache/epub/10/pg10.rdf
...
x cache/epub/9998/pg9998.rdf
x cache/epub/9999/pg9999.rdf
x cache/epub/999999/pg999999.rdf
...
```

Esto nos deja en `cache/epub/` un montón de directorios numerados:

```
$ ls data/cache/epub/ | head -n 4
0
1
10
100
$ ls data/cache/epub/ | tail -n 4
9999
999999
DELETE-52276
DELETE-55495
```

Por ejemplo, aquí están los contenidos de [data/cache/epub/132/pg132.rdf](/tema3-web/pg132)
